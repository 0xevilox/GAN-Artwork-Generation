# Artwork Generation Using Deep Convolutional GAN (DCGAN), Conditional GAN (CGAN), and Creative Adversarial Network (CAN)

## Introduction
This project focuses on generating realistic artwork paintings using three different Generative Adversarial Network (GAN) models: Deep Convolutional GAN (DCGAN), Conditional GAN (CGAN), and Creative Adversarial Network (CAN). The models are implemented in PyTorch and trained on the WikiArt dataset resized to 64x64 pixels. This documentation provides an overview of the architectures, training procedures, and results obtained from each model.

## Dataset
The WikiArt dataset consists of a diverse collection of artwork paintings across various styles and genres. The dataset is preprocessed and resized to 64x64 pixels to facilitate training with the GAN models.


## Model Architectures
Deep Convolutional GAN (DCGAN):

Architecture: Based on the paper by A. Radford, L. Metz, and S. Chintala.
Generator: Utilizes transposed convolutional layers for upscaling and deconvolution.
Discriminator: Employs convolutional layers for feature extraction and classification.
Conditional GAN (CGAN):

Architecture: Inspired by the paper by M. Mirza and S. Osindero.
Generator: Conditioned on additional information (e.g., style labels) to generate artwork paintings with specific attributes.
Discriminator: Adapts to the conditional input for improved discrimination between real and generated images.
Creative Adversarial Network (CAN):

Architecture: Based on the paper by A. Elgammal et al.
Generator: Incorporates creativity by learning about styles and deviating from style norms, encouraging novel and diverse artwork generation.
Discriminator: Evaluates the creativity and deviation from norms in generated artwork.
Training Procedure
Each model is trained using the Adam optimizer with a learning rate of X for Y epochs.
Batch size: Z
Loss functions: Adversarial loss (GAN loss) and additional losses (e.g., feature matching loss for DCGAN, conditional loss for CGAN).
Training progress is monitored using metrics such as generator and discriminator losses, image quality, style diversity, and creativity.
Results and Evaluation
Visual Quality: Generated artwork samples showcase the visual quality and fidelity achieved by each model.
Style Diversity: Analysis of the diversity in artwork styles generated by the models, demonstrating their ability to capture and reproduce various artistic styles.
Creativity Assessment: Evaluation of the creative output generated by the CAN model, highlighting its capability to deviate from style norms and produce novel artwork.

## Conclusion
In conclusion, this project demonstrates the effectiveness of DCGAN, CGAN, and CAN models in generating realistic and diverse artwork paintings. The implementation in PyTorch, combined with the WikiArt dataset, provides a robust framework for exploring generative art and creative expression through deep learning techniques.

